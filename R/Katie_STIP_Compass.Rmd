---
title: "Hackathon - STIP Compass"
output: html_document
date: '2022-05-24'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.showtext = TRUE)
```

#SET UP
```{r}
### general options
Sys.setenv(LANG = "en")
options("scipen" = 100, "digits" = 4) # override R's tendency to use scientific notation

### Clean workspace
#rm(list=ls())
#graphics.off()

### Load packages (maybe need to be installed first)
# Standard
library(tidyverse) # General DS toolkit
library(magrittr) # For advanced piping

# Databases
#library(DBI) # GEneral R database interface
#library(RPostgres) # PostgreSQL interface driver 
library(dbplyr) # for dplyr with databases

# Dataviz
#library(kableExtra)
#library(treemapify)
library(gplots)
library(ggraph) #Network
#library(ggrepel)
#library(hrbrthemes) #Beautiful theme
#library(viridis) #Beautiful theme
#library(car) #scatterplot() package
#library(plotly) #interactive plots
#library(htmlwidgets) #interactive widgets 
library(svglite)  # for saving pictures in svg clearer format (can convert to png) 
library(rsvg)
#library(ggpubr)
#library(interplot)
library(kableExtra) #Format the table

#Text Processing
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(wordcloud)
library(wordcloud2)
library(VennDiagram)
library(tidytext) #Text pre-processing
library(SnowballC) #Word stemming

#Survival plot
library(survival)
library(survminer) #For colorful survival plot use with ggsurvplot()

#Network
library(tidygraph)


# Economic Complexity
library(EconGeo)

#Regression
library(plm)
#library(stargazer) #beautiful Latex, HTML, ASCII tables
library(lmtest) #coeftest()
#library(sandwich) #vcovHC
#library(sjPlot) # Plot results (tab_model)
#library(sjmisc) #For descr() and other fun complementary with dplyr http://strengejacke.de/sjmisc-cheatsheet.pdf
#library(html2latex) # Convert tab_model html tables to tex and pdf 
#library(bife) #Fixed effects logit/probit
#library(stargazer)

#Solve R Fatal Error
#options("error" = function () {
#.rs.recordTraceback(TRUE, 5, .rs.enqueueError)
#})
```

# 1. Descriptive Text: STIP Compass surveys
More data: https://stip.oecd.org/stip/pages/stipDataLab
```{r}
library(readr)


url <- 'https://stip.oecd.org/assets/downloads/STIP_Survey.csv'   #2021

#download the dataset Or download from the link above
download.file(url, destfile = 'stip_2021.csv', mode = 'wb')


#load the dataset into our working environment
stip_0 <- read_delim('stip_2021.csv', '|', escape_double = FALSE, trim_ws = TRUE)

```

Prepare the dataset
```{r}
#Most columns with info on instruments start with the Letter 'F' followed by a number & a few more instruments
instrument <- stip_0[,grepl('^[F][0-9]', (names(stip_0)))] %>% cbind(stip_0[,!grepl('Instrument', (names(stip_0)))])
```

```{r}
# Removes all columns with instrument (start with F)
stip <- stip_0[,!grepl('^[F][0-9]', (names(stip_0)))]

#There are a few more columns with information on instruments. We remove them, too for the sake of coherence
stip <- stip_0[,!grepl('Instrument', (names(stip_0)))]

#This code identifies unique Initiative IDs. When multiple rows have the same initiative IDs, it retains only one of them. Since we have already removed all the information on instruments, no information is lost by retaining each initiative only once
stip <- stip %>%
  distinct(InitiativeID, .keep_all = T)

names(stip)
```

The first row of the dataset does not contain actual data, but descriptions of the variables. We extract this row and create a dataframe from it that we call our codebook. 
```{r}
codebook <- as.data.frame(t(stip[1,])) %>%
  rownames_to_column()

names(codebook) <- c('Variable', 'Code')

#...remove the first row from the dataset: 
stip <- stip[-1, ]

#take a look at the codebook
head(codebook) #The first few variables names are mostly self-explanatory 
```

Add some new columns
```{r}
stip <- stip %>%
  mutate(InitiativeID = as.numeric(gsub('http://stip.oecd.org/2021/data/policyInitiatives/', '', stip$InitiativeID))) %>%
  mutate(year_length = as.numeric(EndDateYear)-as.numeric(StartDateYear)) %>%
  relocate(year_length, .after = EndDateYear)

```

Combine short description with objectives to a new all_texts column
```{r}
#this creates a vector with the names of all columns we wish to unite
cols <- c('ShortDescription', names(stip)[grepl('Objectives', names(stip))])

#this unites these columns in the new column 'all_texts'
stip$all_texts <- apply(stip[ ,cols], 1, paste, collapse = ' ')

#take a look at the first few new documents (i.e. the pieces of textual data that we will analyse)
head(stip$all_texts, 3)
```

Create corpus
```{r}
stip_corp <- corpus(stip, docid_field = 'InitiativeID', text_field = 'all_texts')

#take a look
stip_corp
```

```{r}
stip_dfm <- dfm(stip_corp)

stip_dfm <- stip_dfm %>%
  dfm_remove(stopwords('english'), min_nchar = 3) %>%
  dfm_remove(pattern = '(?<=\\d{1,9})\\w+', valuetype = 'regex' )

#Take a look: This dfm has still more 10000 features
stip_dfm  
```
Reduce the number of features in the dfm during pre-processing.
```{r}
stip_dfm  <- stip_dfm %>% 
  dfm_wordstem() %>% #stem the dfm
  dfm_trim(min_docfreq = 0.01,  docfreq_type = 'prop') # retain only words included in at least 1% of documents
  #dfm_subset(ntoken(stip_dfm) >= 10) # remove documents with less than 10 words

#Take a look again: Now, we have substantially reduced the number of features to less than 1000
stip_dfm
```
The dataset also contains a column with innovation-related keywords for each initiative (from a dedicated vocabulary of concepts). This is highly useful for the analysis, so we generate a second dfm from it. We generate this dfm in another way than the previous one since the unit of analysis in this case are not words, but keywords often consisting of multi-word expressions.


```{r}
tag_dfm <- tokenizers::tokenize_regex(stip$Tags, pattern = '¬') %>%
  as.tokens() %>%
  dfm() %>%
  dfm_remove(min_nchar = 3) 

rownames(tag_dfm) <- stip$InitiativeID
docvars(tag_dfm) <- stip

tag_dfm
```
Detail of tag_dfm
```{r}
ndoc(tag_dfm) #number of docs
nfeat(tag_dfm) #number of features
head(docnames(tag_dfm))
head(ntoken(tag_dfm),10) #number of features per doc
features <- featnames(tag_dfm) %>% as.data.frame()

features_per_doc <- ntoken(tag_dfm) %>% as.data.frame()



```

```{r}
Tag_csv <- tag_dfm %>% as.data.frame()
#write.csv(Tag_csv,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\Tag_csv.csv"), row.names = FALSE)
```

### Wordcloud & Hclust
```{r}
textplot_wordcloud(stip_dfm)
```

```{r}
textplot_wordcloud(tag_dfm)
```
How does language in different subsets of policy initiatives differ?
```{r}
#e.g. From the codebook: TH31  'Financial support to business R&D and innovation' 
fs_keyness <- textstat_keyness(stip_dfm, 
                              target = stip_dfm$TH31 == 1)
textplot_keyness(fs_keyness)
```
Considering only documents in the dataset linked to this theme and then compare the initiatives from Canada to all the others.
```{r}
fs_dfm <- dfm_subset(stip_dfm, stip_dfm$TH31 == 1) 
  
can_keyness <- textstat_keyness(dfm_remove(fs_dfm, pattern = c('canada', 'canadian')), 
                              target = fs_dfm$CountryCode == 'CAN')

textplot_keyness(can_keyness)
```
Compare the documents from different countries.
CAUTION: 1) The comparison below does not consider whether some countries report more information on particular themes or survey questions than others. 2) This analysis assigns similar weight to all initiatives
```{r}
#create a dfm that merges all documents by country
dfm_countries <- dfm_group(stip_dfm, groups = CountryCode)

#computes distances between documents from different countries
tstat_dist <- as.dist(textstat_dist(dfm_countries))

#cluster countries based on these distances
user_clust <- hclust(tstat_dist)

plot(user_clust, cex = 0.5)
```


Find duplicated stip (No duplicated InitiativeID but NameEnglish)
```{r}
stip %>% 
  group_by(NameEnglish) %>% 
  filter(n()>1) %>% 
  ungroup()
```


## 1.1. Searching 'Co-creation'&'Knowledge transfer' keywords 
These keywords are defined as the root (main) keywords
```{r}
# Keywords for co-creation
root_key_co <- list('brain circulation','engagement','challenge','in-kind','trust$','co-funding','collaborative','multilateral','platforms','joint','partnership','cooperation','value chain','tacit','triangle','mobility','triple helix','co-','open science')

# Keywords for knowledge transfer
root_key_kt <- list('bilateral','unidirectional','one-off','linear','voucher','short-term','transfer','contract','copyright','property rights','diffusion','flows','sharing','commercialisation','secrets','absorptive','licens','spin-off','vocational skills','adopt','brain drain')

# Keywords that can apply to both
root_key_neutral <- list('cluster','network','patent','industry orientation','incubat','start-up','intellectual property','skills development','learning','schumpeter','collaboration','spillover','trademark','science-industry links','access','adapt','brain gain','user-driven','user-producer','product development')



root_key_all <- list('brain circulation','engagement','challenge','in-kind','trust$','co-funding','collaborative','multilateral','platforms','joint','partnership','cooperation','value chain','tacit','triangle','mobility','triple helix','co-',
                                                'bilateral','unidirectional','one-off','linear','voucher','short-term','transfer','contract','copyright','property rights','diffusion','flows','sharing','commercialisation','secrets','absorptive','licens','spin-off','vocational skills','adopt','brain drain',

'cluster','network','patent','industry orientation','incubat','start-up','intellectual property','skills development','learning','schumpeter','collaboration','spillover','trademark','science-industry links','access','adapt','brain gain','user-driven','user-producer','product development')
 

#Wanted <- stip %>% 
 # select(InitiativeID,NameEnglish,CountryLabel,StartDateYear,Tags) %>%
 # drop_na(Tags) %>% 
  #mutate(wanted = ifelse(str_detect(Tags,key),1,0))

#Select features
Cocreate_features <- dfm_select(tag_dfm, pattern = root_key_co, valuetype = 'regex') 
#topfeatures(Cocreate_features)
featnames(Cocreate_features)

KT_features <- dfm_select(tag_dfm, pattern = root_key_kt, valuetype = 'regex') 
#topfeatures(KT_features)
featnames(KT_features)

NT_features <-  dfm_select(tag_dfm, pattern = root_key_neutral, valuetype = 'regex') 
#topfeatures(NT_features)
featnames(NT_features)

All_features <- dfm_select(tag_dfm, pattern = root_key_all, valuetype = 'regex') 
featnames(All_features)
```

Subset documents containing at least 1 keyword
```{r}
Sub_doc_co <- Cocreate_features %>% dfm_subset(ntoken(.) > 0) 

Sub_doc_kt <- KT_features %>% dfm_subset(ntoken(.) > 0) 

Sub_doc_neutral <- NT_features %>% dfm_subset(ntoken(.) > 0) 

Sub_doc <- All_features %>% dfm_subset(ntoken(.) > 0) 
```

### calculate TFIDF (Word relevance to particular documents)
TFIDF: The higher the score, the more relevant that word is in that particular document.
```{r}
Sub_doc_co %>% dfm_tfidf(scheme_tf = "prop") %>%  topfeatures(n = 20)
```

## 1.2 Word cloud for each category
Wordcloud of keywords of all documents that contain at least one relevant keyword in the 'Co-creation', 'Knowledge Transfer', and 'Neutral' categories.
Co_cloud_tfidf consists of keywords co-occurred with at least one of the 'Co-creation' category. 
```{r}
All_cloud <- Sub_doc %>%
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() 

rownames(All_cloud) <- rownames(Sub_doc)
```


```{r}
Co_cloud_tfidf <- Sub_doc_co %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm()  %>%
  dfm_tfidf()
  # dfm_trim() #trim out terms that are less frequent than 10 (for dfm with binary features)

rownames(Co_cloud_tfidf) <- rownames(Sub_doc_co)

Co_cloud <- Sub_doc_co %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() 

rownames(Co_cloud) <- rownames(Sub_doc_co)
```

Each policy initiative in Doc_id is named text+number
```{r}
docnames(Co_cloud)[1:10]
```

```{r}
docfreq(Co_cloud)[1:10]
```

```{r}
featfreq(Co_cloud)[1:10]
```


```{r}
Co_cloud_tfidf %>%  topfeatures(n = 20)
```

```{r}
png(filename = paste0( getwd(), "/Plots/Keywords/Co_creation_tfidf.png"),width = 1000, height = 1000)

Co_cloud_tfidf %>%
 textplot_wordcloud()
 
mtext("Cocreation-associated keywords frequency: TFIDF",
      side=3, 
      line=1, 
      at= 0.5, 
      adj= 0.5, 
      cex=3) 
dev.off()
```

```{r}
KT_cloud_tfidf <- Sub_doc_kt %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() %>%
  dfm_tfidf() 
 # dfm_trim(min_termfreq = 20, termfreq_type = "rank") #trim out terms that are less frequent than 10
rownames(KT_cloud_tfidf) <- rownames(Sub_doc_kt)

KT_cloud <- Sub_doc_kt %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() 
rownames(KT_cloud) <- rownames(Sub_doc_kt)
```

```{r}
png(filename = paste0( getwd(), "/Plots/Keywords/Knowledge_transfer_tfidf.png"),width = 1000, height = 1000)
KT_cloud_tfidf %>%
  textplot_wordcloud()

mtext("Knowledge transfer-associated keywords frequency: TFIDF",
      side=3, 
      line=1, 
      at= 0.45, #adjust horizontal line here
      adj= 0.5, 
      cex=2) 

dev.off()
```


```{r}
NT_cloud_tfidf <- Sub_doc_neutral %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() %>%
  dfm_tfidf() 
 # dfm_trim(min_termfreq = 20, termfreq_type = "rank") #trim out terms that are less frequent than 10
rownames(NT_cloud_tfidf) <- rownames(Sub_doc_neutral)

NT_cloud <- Sub_doc_neutral %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() 
rownames(NT_cloud) <- rownames(Sub_doc_neutral)
```

```{r}
png(filename = paste0( getwd(), "/Plots/Keywords/Neutral_tfidf.png"),width = 1000, height = 1000)
NT_cloud_tfidf %>% textplot_wordcloud()
  
mtext("Neutrally associated keywords frequency: TFIDF",
      side=3, 
      line=1, 
      at= 0.45, #adjust horizontal line here
      adj= 0.5, 
      cex=3) 

dev.off()
```

Download Root+sub keywords files of each category
```{r}
doc_cocreate <- Sub_doc_co %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm()  

rownames(doc_cocreate) <- rownames(Sub_doc_co)

doc_cocreate <- doc_cocreate %>% as.data.frame() %>%
  pivot_longer(cols = 2:(length(featnames(doc_cocreate))+1), names_to = 'keyword',values_to = 'presence') %>%
  filter(presence == 1) %>% select(-presence) %>%
  mutate(Category = 'Co-creation')


doc_KT <- Sub_doc_kt %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() 

rownames(doc_KT) <- rownames(Sub_doc_kt)

doc_KT <- doc_KT %>%
  as.data.frame() %>%
  pivot_longer(cols = 2:(length(featnames(doc_KT))+1), names_to = 'keyword',values_to = 'presence') %>%
  filter(presence == 1) %>% select(-presence) %>%
   mutate(Category = 'Knowledge transfer')


doc_NT <- Sub_doc_neutral %>% 
  docvars("Tags") %>% 
  tokenizers::tokenize_regex(pattern = '¬') %>%
  as.tokens() %>%
  dfm() 

rownames(doc_NT) <- rownames(Sub_doc_neutral)

doc_NT <- doc_NT %>%
  as.data.frame() %>%
  pivot_longer(cols = 2:(length(featnames(doc_NT))+1), names_to = 'keyword',values_to = 'presence') %>%
  filter(presence == 1) %>% select(-presence) %>%
  mutate(Category = 'Neutral')


doc_key_cat <- rbind(doc_cocreate,doc_KT,doc_NT)

write.csv(doc_key_cat,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\doc_key_cat.csv"), row.names = FALSE)

```


Removing the -re-assigned (root) keyword, so that we can visualize only the co-occurred keywords.
```{r}
png(filename = paste0( getwd(), "/Plots/Keywords/Co_creation_category_related.png"),width = 3000, height = 3000)
Co_cloud_tfidf %>% dfm_remove(pattern = root_key_co, valuetype = "regex") %>% textplot_wordcloud()
dev.off()
```


```{r}
png(filename = paste0( getwd(), "/Plots/Keywords/Knowledge_transfer_category_related.png"),width = 2000, height = 2000)
KT_cloud_tfidf %>% dfm_remove(pattern = root_key_kt, valuetype = "regex") %>% textplot_wordcloud()
dev.off()
```

## 1.3 Re-categorize the selected keywords (Engineering!)
Filter keywords present/absence in each category
```{r}
Co_cloud_tfidf %>% as.data.frame() %>% pivot_longer(cols = 2:(length(featnames(Co_cloud_tfidf))+1), names_to = 'keywords', values_to = 'tfidf')
```

This only shows whether the keywords show up in at least one document in the category
```{r}
#Dataframe for co-creation category keywords (both main keywords and associated keywords)
binary_cat <- featnames(Co_cloud_tfidf) %>% as.tibble() %>% mutate(Cocreate_presence = 1) %>% 
  #Join with the dataframe of KT and NT category keywords (both main keywords and associated keywords)
  full_join(featnames(KT_cloud_tfidf) %>% as.tibble() %>% mutate(KT_presence = 1), by = 'value') %>% 
  full_join(featnames(NT_cloud_tfidf) %>% as.tibble() %>% mutate(NT_presence = 1), by = 'value') %>%
  replace_na(list(Cocreate_presence = 0, KT_presence = 0, NT_presence = 0))#Replace NA with logic 0
  # filter(Cocreate == 1 & KT == 0 & NT == 0) #Filter only keywords associated with co-creation but not knowledge transfer 

binary_cat
```

1. Make columns (XX_presence) that indicates whether the main and sub keywords present in each category in each document.
2. Then make another set of columns (XX_belong) that only indicates whether that keywords are originally belong to that particular category (the root keywords defined in key_co, key_kt,key_neutral)
  * Cocreate_features is a dfm() containing the root key terms in key_co

Data frame of words and tfidf:
- 358,084 documents with 654 keywords each
- if presence is 0, means they keyword does not occur in that category. 
- absence keyword always return tfidf = 0.

```{r}
#Convert to data frame
keyword_dat <- 
  as.data.frame(Co_cloud_tfidf) %>% 
  pivot_longer(cols = 2:(length(featnames(Co_cloud_tfidf))+1),names_to = 'name', values_to = 'tfidf_cocreate') %>%
    #Join the Co-creation dfm that has tfidf value and binary values
  full_join( as.data.frame(Co_cloud) %>% pivot_longer(cols = 2:(length(featnames(Co_cloud_tfidf))+1),names_to = 'name', values_to = 'Cocreate_presence'), by = c('doc_id','name')) %>%
  #Join the Knowledge Transfer dfm that has tfidf value and binary values
  full_join(as.data.frame(KT_cloud_tfidf) %>% 
              pivot_longer(cols = 2:(length(featnames(KT_cloud_tfidf))+1),names_to = 'name', values_to = 'tfidf_knowledge_transfer'), by = c('doc_id','name'))%>%
  full_join(as.data.frame(KT_cloud) %>% 
              pivot_longer(cols = 2:(length(featnames(KT_cloud_tfidf))+1),names_to = 'name', values_to = 'KT_presence'), by = c('doc_id','name')) %>%
  #Join the Neutral dfm that has tfidf value and binary values
  full_join(as.data.frame(NT_cloud_tfidf) %>% 
              pivot_longer(cols = 2:(length(featnames(NT_cloud_tfidf))+1),names_to = 'name', values_to = 'tfidf_neutral'), by = c('doc_id','name')) %>%
  full_join(as.data.frame(NT_cloud) %>% 
              pivot_longer(cols = 2:(length(featnames(NT_cloud_tfidf))+1),names_to = 'name', values_to = 'NT_presence'), by = c('doc_id','name')) %>%
  #Detect whether the keyword is the root words
    mutate(Cocreate_root = ifelse(name %in% featnames(Cocreate_features),1,0),
         KT_root = ifelse(name %in% featnames(KT_features),1,0),
         NT_root = ifelse(name %in% featnames(NT_features),1,0)) %>%
  #Relocate columns
    relocate(tfidf_knowledge_transfer, .after = tfidf_cocreate) %>%
    relocate(tfidf_neutral, .after = tfidf_knowledge_transfer) %>%
  #Replace NA with zero
  replace_na(list(Cocreate_presence = 0, KT_presence = 0, NT_presence = 0))
  
  
  
  # Columns indicating the presence of root + sub keywords
  #mutate(Cocreate_presence = ifelse(name %in% featnames(Co_cloud_tfidf),1,0),
  #       KT_presence = ifelse(name %in% featnames(KT_cloud_tfidf),1,0),
  #       NT_presence = ifelse(name %in% featnames(NT_cloud_tfidf),1,0)) %>%
  # Columns indicating the presence of only the root keywords


keyword_dat
```


Which documents have high/low score of cumulative tfidf of relevant word?
```{r}
keyword_dat %>% group_by(doc_id) %>% 
  summarise(Sum_cocreate = sum(tfidf_cocreate, na.rm = T),
            Sum_KT = sum(tfidf_knowledge_transfer, na.rm = T),
            Sum_neutral = sum(tfidf_neutral, na.rm = T)) 
```
Some documents contain sub and root keyword(s) that only present in Co-creation category, sometimes both or all, sometimes none.  
```{r}
keyword_dat %>% group_by(doc_id,Cocreate_presence,KT_presence,NT_presence) %>% 
  summarise(Sum_cocreate = sum(tfidf_cocreate, na.rm = T),
            Sum_KT = sum(tfidf_knowledge_transfer, na.rm = T),
            Sum_neutral = sum(tfidf_neutral, na.rm = T))
```

The frequency of words is the highest if it is a root word in that particular category.
However, This may not be necessary for TFIDF since TFIDF measures the originality of the words in a separate category. 
Example calculation for cumulative TFIDF in one category: featfreq(Co_cloud) * log(ndoc(Co_cloud) / docfreq(Co_cloud), base = 10) --> incubators = 5*log(487/5) = 9.942 in total. 
While the frequency it appears in one document is  1*log(487/5) =1.988.

Note: TFIDF calculation is two-folded normalized. First, each document is normalized to length 1 = no bias for shorter or longer document. Second, IDF is cross-document normalized, putting less weight on common terms and more on rare terms. Therefore, TFIDF of each category can be compared.  
```{r}

Keyword_categories <- keyword_dat %>% 
  group_by(name,Cocreate_root,KT_root,NT_root) %>%
  summarise(freq_cocreate = sum(Cocreate_presence), #Tells how many documents have this keyword
            freq_KT = sum(KT_presence),
            freq_NT = sum(NT_presence),
            Total_doc = sum(freq_cocreate,freq_KT,freq_NT),
            Tfidf_cocreate = sum(tfidf_cocreate, na.rm = T),
            Tfidf_KT = sum(tfidf_knowledge_transfer, na.rm = T),
            Tfidf_neutral = sum(tfidf_neutral, na.rm = T)) %>%
 
  #Assigned new category 
  mutate(assigned_category = case_when(Tfidf_KT > Tfidf_cocreate & Tfidf_KT > Tfidf_neutral ~ 'Knowledge Transfer',
                                  Tfidf_cocreate > Tfidf_KT & Tfidf_cocreate > Tfidf_neutral~ 'Co-creation',
                                  Tfidf_neutral > Tfidf_KT & Tfidf_neutral > Tfidf_cocreate~ 'Neutral')) %>%
  #Whether that key is the originally assigned keywords (root key) or they are the co-occurred keys
  mutate(attribute_2 = case_when(Cocreate_root == 1 & KT_root == 0 & NT_root == 0 ~ 'Cocreate Root Key',
                                 Cocreate_root == 0 & KT_root == 1 & NT_root == 0 ~ 'Knowledge Transfer Root Key',
                                 Cocreate_root == 0 & KT_root == 0 & NT_root == 1 ~ 'Neutral Root Key',
                                 Cocreate_root == 0 & KT_root == 0 & NT_root == 0 ~ 'Co-occurred Key')) %>%
  ungroup()



# tag_dfm --> network with attributes --> root key all

#left_join new keyword categories with root key all's network data

```

```{r}
write.csv(Keyword_categories,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\keyword_data_2.csv"), row.names = FALSE)
```

### 1.4 Characterize the policies
#### Method 1: TFIDF
Not a good choice because TFIDF is high for all categories, meaning that there's a large overlapping extent between Co-creation and Knowledge Transfer and the boundary is unclear. 
```{r}
doc_cat <- tag_dfm %>% as.data.frame() %>% 
  pivot_longer(2:(length(featnames(tag_dfm))+1),names_to = 'name', values_to = 'presence') %>%
  filter(presence == 1) %>% select(-presence) %>%
  left_join(Keyword_categories, by = 'name') %>%
  
  #Categorize based on the highest TFIDF values
  #Calculate total TFIDF in each document for each category 
  group_by(doc_id) %>%
  summarise(Tfidf_cocreate_sum = sum(Tfidf_cocreate, na.rm = TRUE),
            Tfidf_KT_sum = sum(Tfidf_KT, na.rm = TRUE),
            Tfidf_neutral_sum = sum(Tfidf_neutral, na.rm = TRUE)) %>%
  ungroup() %>%
  
  #Assigning the categories
  mutate(assigned_category = case_when(
    Tfidf_cocreate_sum > Tfidf_KT_sum & Tfidf_cocreate_sum > Tfidf_neutral_sum ~ 'Co-creation',
    Tfidf_KT_sum > Tfidf_cocreate_sum & Tfidf_KT_sum > Tfidf_neutral_sum ~ 'Knowledge Transfer',
    Tfidf_neutral_sum > Tfidf_KT_sum & Tfidf_neutral_sum > Tfidf_cocreate_sum ~ 'Both')) %>%
  
  #Join the data with STIP initative datset
  mutate(doc_id = as.numeric(doc_id)) %>% 
  left_join(stip, by = c('doc_id' = 'InitiativeID'))
  
```

```{r}
png(filename = paste0( getwd(), "/Plots/Keywords/Cat_doc.png"),width = 2000, height = 2000)

doc_cat %>% filter(assigned_category != 'Both') %>% 
  group_by(assigned_category,StartDateYear) %>% 
  drop_na(StartDateYear) %>%
  summarise(N = n()) %>% arrange(desc(StartDateYear)) %>%
  ggplot(aes(x=StartDateYear,y=N, fill = assigned_category)) +
  geom_bar(stat = "identity") +
  xlab("Year") +
  ylab("Number of documents/policy initiatives") +
   theme(axis.text.x = element_text(size = 30,angle = 45),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30)
         ) 


dev.off()
```
```{r}
Cocreate_doc_group1 <- doc_group1 %>% filter(assigned_category == 'Co-creation')
KT_doc_group1 <- doc_group1 %>% filter(assigned_category == 'Knowledge Transfer')
```

#### Method 2: Keywords from the Venn Diagram (3.) and then weigh them
Without ranking based on keyword's significance, because some keywords might be new.
```{r}
doc_cat_2 <- tag_dfm %>% as.data.frame() %>% 
  pivot_longer(2:(length(featnames(tag_dfm))+1),names_to = 'name', values_to = 'presence') %>%
  filter(presence == 1) %>% select(-presence) %>%
  mutate(Cocreate_presence = ifelse(name %in% Cocreate_key$Co_creation,1,0),
         KT_presence = ifelse(name %in% KT_key$Knowledge_transfer,1,0),
         Overlap_presence = ifelse(name %in% Overlap_key$Overlap,1,0)) %>%
  group_by(doc_id) %>% summarise(Total_key = n(),
                                 Cocreation_p = sum(Cocreate_presence)/Total_key,
                                 KT_p = sum(KT_presence)/Total_key,
                                 Overlap_p = sum(Overlap_presence)/Total_key) %>%
  #Assign a category
  mutate(assigned_category = case_when(Cocreation_p + Overlap_p > KT_p + Overlap_p ~ 'Co-creation',
                                       Cocreation_p + Overlap_p < KT_p + Overlap_p ~ 'Knowledge Transfer',
                                       Overlap_p > Cocreation_p + KT_p | Cocreation_p == KT_p ~ 'Both')) %>%
  #Join the data with STIP initative datset
  mutate(doc_id = as.numeric(doc_id)) %>% 
  left_join(stip, by = c('doc_id' = 'InitiativeID'))
  

```
```{r}
write.csv(doc_cat_2,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\doc_cat_2.csv"), row.names = FALSE)
```

### 1.5 Data description/Statistics for policy in Cocreation and Knowledge Transfer category
Number of docs in each category
```{r}
doc_cat_2 %>% group_by(assigned_category) %>% summarise( N = n())
```
Number of countries

```{r}
doc_cat_2 %>% group_by(CountryLabel,assigned_category) %>% summarise( N = n())
```


Total docs count each category over time
```{r}
png(filename = paste0( getwd(), "/Plots/Initiatives/Cat_doc_2.png"),width = 2000, height = 2000)

doc_cat_2 %>% filter(assigned_category != 'Both') %>% 
  group_by(assigned_category,StartDateYear) %>% 
  drop_na(StartDateYear) %>%
  summarise(N = n()) %>% arrange(desc(StartDateYear)) %>%

  ggplot(aes(x=StartDateYear,y=N, fill = assigned_category)) +
  geom_bar(stat = "identity") +
  xlab("Year") +
  ylab("Number of documents/policy initiatives") +
   theme(axis.text.x = element_text(size = 30,angle = 45),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30)
         ) 

dev.off()

```

Difference in doc count
```{r}
png(filename = paste0( getwd(), "/Plots/Initiatives/Cat_doc_2.png"),width = 2000, height = 2000)
  
doc_cat_2 %>%
  group_by(StartDateYear,assigned_category) %>%
  drop_na(StartDateYear) %>%
  summarise(N = n()) %>%
  
  #calculate total initiatives(Both+Co-create+Knowledge Transfer)
  left_join(doc_cat_2 %>%
  group_by(StartDateYear) %>%
  summarise(Total_initiatives = n()), by = 'StartDateYear') %>%
  
  #Calculate proportional differences
  group_by(StartDateYear) %>%
  filter(assigned_category != 'Both') %>%
  summarise(Diff_p = 100*diff(N)/Total_initiatives) %>%
  distinct(StartDateYear, .keep_all = TRUE) %>%
  #Make category again so that you can them the same color in fill = 
  mutate(Category = ifelse(Diff_p < 0,"co-create", "knowledge transfer")) %>%
  ungroup() %>%
  
  ggplot(aes(x=StartDateYear,y=Diff_p, fill = StartDateYear)) +
  geom_bar(stat = "identity") +
  xlab("Year") +
  ylab("Difference in proportion of policy initiatives (%)") +
   theme(axis.text.x = element_text(size = 30,angle = 45),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30),
         legend.position = 'none'
         ) 

dev.off()

```

Line graph of no. doc. for each category
```{r}
png(filename = paste0( getwd(), "/Plots/Initiatives/line_graph.png"),width = 1500, height = 1500)

doc_cat_2 %>%
  group_by(StartDateYear,assigned_category) %>%
  drop_na(StartDateYear) %>%
  summarise(N = n()) %>%
  filter(assigned_category != 'Both') %>%

  ggplot(aes(x=StartDateYear,y=N, group = assigned_category, linetype = assigned_category)) +
  geom_line(aes(color = assigned_category))+
  geom_point(aes(color = assigned_category)) +
  xlab("Year") +
  ylab("Number of policy initiatives") +
   theme(axis.text.x = element_text(size = 20,angle = 45),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30)
         ) 


dev.off()
```



Cumulative TFIDF of doc in each category
```{r}
#doc_cat has tfidf. Use the assigned_category from doc_cat_2
doc_cat %>% select(-assigned_category) %>%
  left_join(doc_cat_2 %>% select(doc_id,assigned_category), by = 'doc_id') %>% 
  
  filter(assigned_category != 'Both') %>%
  group_by(StartDateYear) %>% 
  drop_na(StartDateYear) %>%
  summarise(sum_tfidf_cocreate = sum(Tfidf_cocreate_sum),
            sum_tfidf_KT = sum(Tfidf_KT_sum)) %>%
  pivot_longer(2:3,values_to = 'tfidf', names_to = 'category') %>%
  ggplot(aes(x=StartDateYear,y=tfidf, group = category, linetype = category)) +
  geom_line()
```

```{r}
#library(survival)
#library(survminer) #For colorful survival plot use with ggsurvplot()
png(filename = paste0( getwd(), "/Plots/Keywords/Survival_1.png"),width = 700, height = 700)

survival <- doc_cat_2 %>% select(1:15) %>% 
  filter(assigned_category != 'Both') %>%
  #status = 1 = censored (year_length is NA); = 2 = dead.
  mutate(status = case_when(is.na(year_length) == TRUE ~ 1,
                            is.na(year_length) == FALSE ~ 2)) %>%
  mutate(StartDateYear = as.numeric(StartDateYear),
         EndDateYear = as.numeric(EndDateYear)) 

sfit <- survfit(Surv(survival$year_length,survival$status)~assigned_category, data=survival)
#summary(sfit, times=seq(0, 100, 5))
ggsurvplot(sfit,conf.int=TRUE, pval=TRUE, risk.table=TRUE, 
           legend.labs=c("Co-creation", "Knowledge Transfer"), legend.title="Category",  
           palette=c("dodgerblue2", "orchid2"), 
           title="Kaplan-Meier Curve for length of project", 
           risk.table.height=.15)

dev.off()
```

##1.6 Analyze policy text
Create N-grams wordcloud for each assigned_category
```{r}
##Remove NA and <br/> in all_texts by adding 'NA' in the stop words so that it can be removed
#stop_words %<>% rbind(word = 'na', word = 'br')
#Preprocessing 'Co-creation'
doc_cat_2 %>%
  filter(assigned_category == 'Co-creation') %>%
#Bi-grams (change word --> bigram and token = 'words' to = 'ngrams' with n = X)
  unnest_tokens(word, all_texts, token = 'words') %>%
  anti_join(stop_words, by = 'word') %>%
#Stemming
  mutate(stem = wordStem(word)) %>%
  count(word) %>%
#Wordcloud
  with(wordcloud(word, n, 
                 max.words = 50, 
                 color = "blue"))


#all_texts <- as.data.frame(doc_cat_2$all_texts)
```

#### Bigram
```{r}
png(filename = paste0( getwd(), "/Plots/Texts/Cocreate_bigram.png"),width = 800, height = 800)
#Preprocessing 'Co-creation'
doc_cat_2 %>%
  filter(assigned_category == 'Co-creation') %>%
#Bi-grams (change word --> bigram and token = 'words' to = 'ngrams' with n = X)
  unnest_tokens(bigram, all_texts, token = 'ngrams',n=2) %>%
#Remove stopwords by separating into two words
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  anti_join(stop_words, by = c('word1' = 'word')) %>%
  anti_join(stop_words, by = c('word2' = 'word')) %>%
# Con't remove stopwords but unit them again
  unite(bigram, word1, word2, sep = " ") %>%
#Stemming
  mutate(stem = wordStem(bigram)) %>%
  count(bigram) %>%
#Wordcloud
  with(wordcloud(bigram, n, 
                 max.words = 50, 
                 color = "blue"))

mtext("Cocreation",
      side=3, 
      line=1, 
      at= 0.5, 
      adj= 0.5, 
      cex=3) 
dev.off()

```
```{r}
png(filename = paste0( getwd(), "/Plots/Texts/Knowledge_Transfer_bigram.png"),width = 800, height = 800)
doc_cat_2 %>%
  filter(assigned_category == 'Knowledge Transfer') %>%
#Bi-grams (change word --> bigram and token = 'words' to = 'ngrams' with n = X)
  unnest_tokens(bigram, all_texts, token = 'ngrams',n=2) %>%
#Remove stopwords by separating into two words
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  anti_join(stop_words, by = c('word1' = 'word')) %>%
  anti_join(stop_words, by = c('word2' = 'word')) %>%
# Con't remove stopwords but unit them again
  unite(bigram, word1, word2, sep = " ") %>%
#Stemming
  mutate(stem = wordStem(bigram)) %>%
  count(bigram) %>%
#Wordcloud Top 50 words
  with(wordcloud(bigram, n, 
                 max.words = 30, 
                 color = "blue"))

mtext("Knowledge Transfer",
      side=3, 
      line=1, 
      at= 0.5, 
      adj= 0.5, 
      cex=3) 

dev.off()

```
```{r}
png(filename = paste0( getwd(), "/Plots/Texts/Overlap_bigram.png"),width = 800, height = 800)
doc_cat_2 %>%
  filter(assigned_category == 'Both') %>%
#Bi-grams (change word --> bigram and token = 'words' to = 'ngrams' with n = X)
  unnest_tokens(bigram, all_texts, token = 'ngrams',n=2) %>%
#Remove stopwords by separating into two words
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  anti_join(stop_words, by = c('word1' = 'word')) %>%
  anti_join(stop_words, by = c('word2' = 'word')) %>%
# Con't remove stopwords but unit them again
  unite(bigram, word1, word2, sep = " ") %>%
#Stemming
  mutate(stem = wordStem(bigram)) %>%
  count(bigram) %>%
#Wordcloud Top 50 words
  with(wordcloud(bigram, n, 
                 max.words = 30, 
                 color = "blue"))

dev.off()
```

#### Trigram
```{r}
png(filename = paste0( getwd(), "/Plots/Texts/Cocreate_trigram.png"),width = 1000, height = 1000)
#Preprocessing 'Co-creation'
doc_cat_2 %>%
  filter(assigned_category == 'Co-creation') %>%
#Bi-grams (change word --> bigram and token = 'words' to = 'ngrams' with n = X)
  unnest_tokens(trigram, all_texts, token = 'ngrams',n=3) %>%
#Remove stopwords by separating into 3 words
  separate(trigram, c("word1", "word2","word3"), sep = " ") %>%
  anti_join(stop_words, by = c('word1' = 'word')) %>%
  anti_join(stop_words, by = c('word2' = 'word')) %>%
  anti_join(stop_words, by = c('word3' = 'word')) %>%
# Con't remove stopwords but unit them again
  unite(trigram, word1, word2,word3, sep = " ") %>%
#Stemming
  mutate(stem = wordStem(trigram)) %>%
  count(trigram, sort = TRUE) %>%
#Wordcloud
  with(wordcloud(trigram, n, 
                 max.words = 30, 
                 color = "blue"))

mtext("Co-creation",
      side=3, 
      line=1, 
      at= 0.5, 
      adj= 0.5, 
      cex=3) 

dev.off()

```

```{r}
png(filename = paste0( getwd(), "/Plots/Texts/Knowledge_Transfer_trigram.png"),width = 1000, height = 1000)
#Preprocessing 'Co-creation'
doc_cat_2 %>%
  filter(assigned_category == 'Knowledge Transfer') %>%
#Bi-grams (change word --> bigram and token = 'words' to = 'ngrams' with n = X)
  unnest_tokens(trigram, all_texts, token = 'ngrams',n=3) %>%
#Remove stopwords by separating into 3 words
  separate(trigram, c("word1", "word2","word3"), sep = " ") %>%
  anti_join(stop_words, by = c('word1' = 'word')) %>%
  anti_join(stop_words, by = c('word2' = 'word')) %>%
  anti_join(stop_words, by = c('word3' = 'word')) %>%
# Con't remove stopwords but unit them again
  unite(trigram, word1, word2,word3, sep = " ") %>%
#Stemming
  mutate(stem = wordStem(trigram)) %>%
  count(trigram, sort = TRUE) %>%
#Wordcloud
  with(wordcloud(trigram, n, 
                 max.words = 30, 
                 color = "blue"))

mtext("Knowledge Transfer",
      side=3, 
      line=1, 
      at= 0.5, 
      adj= 0.5, 
      cex=3) 
dev.off()
```

Which countries have higher % co-creation policies?
```{r}
png(filename = paste0( getwd(), "/Plots/Initiatives/By_countries.png"),width = 2000, height = 2000)


doc_cat_2 %>%
  group_by(CountryLabel,assigned_category) %>%
  summarise(N = n()) %>%

  #calculate total initiatives(Both+Co-create+Knowledge Transfer)
  left_join(doc_cat_2 %>%
  group_by(CountryLabel) %>%
  summarise(Total_initiatives = n()), by = 'CountryLabel') %>%
  
  
  #Calculate proportional differences
  group_by(CountryLabel) %>%
  filter(assigned_category != 'Both') %>%
  summarise(Diff_p = 100*diff(N)/Total_initiatives) %>%
  distinct(CountryLabel, .keep_all = TRUE) %>%
  #Make category again so that you can them the same color in fill = 
  mutate(Category = ifelse(Diff_p < 0,"co-create", "knowledge transfer")) %>%
  ungroup() %>%

ggplot(aes(x=reorder(CountryLabel,Diff_p),y=Diff_p,fill=Category)) +
  geom_bar(stat = "identity") +
  xlab("Countries") +
  ylab("Difference in proportion of policy initiatives (%)") +
  scale_fill_discrete(name="Category ",
                      labels = c("Co-create", "Knowledge Transfer")) +
  scale_fill_manual(values = c("#00ba38","#0b8fd3")) +
   theme(axis.text.x = element_text(size = 30,angle =0),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30)
         ) +
  coord_flip()
dev.off()
```

#### Diversity of the target groups?

1) Number of target groups per each category
```{r}

doc_cat_2 %>%
  group_by(doc_id,assigned_category) %>%
  pivot_longer(100:130, names_to = 'Target_group', values_to = 'presence') %>%
  filter(presence == 1) %>%
  summarise(N = n()) %>%
  ungroup() %>%
  group_by(assigned_category) %>%
  summarise(avr_num_actors = mean(N)) %>%
  kbl(longtable = T, booktabs = T) %>%
  kable_classic(full_width = F,font_size = 50) %>%
  column_spec(2, width = "8m") %>%
  save_kable("average_actors.png", self_contained = T)
  
```
```{r}
doc_cat_2 %>%
  group_by(doc_id,assigned_category) %>%
  pivot_longer(100:130, names_to = 'Target_group', values_to = 'presence') %>%
  filter(presence == 1) %>%
  summarise(num_TG = n()) %>%
  ungroup() %>%
  group_by(assigned_category) %>%
  summarise(avr_num_actors = mean(num_TG),
            sd_num_actors = sd(num_TG)) %>%
  ggplot() +
  geom_bar(aes(x = assigned_category, y = avr_num_actors), stat="identity", alpha=0.5)+
    geom_errorbar(aes(x=assigned_category, ymin=avr_num_actors-sd_num_actors, ymax=avr_num_actors+sd_num_actors), width=0.4, colour="orange", alpha=0.9, size=1.3)
```

2) Top countries in each category 
```{r}
#Re-arranged by combining some 'TG's into a bigger category according to STIP classification of target groups
Cocreate_actors <- doc_cat_2 %>%
  select(doc_id,TG9,TG10,TG11,TG12,TG13,TG14,TG15,TG16,TG17,TG18,TG19,TG20,TG21,TG22,TG23,TG24,TG25,TG26,TG27,TG28,TG29,TG30,TG31,TG32,TG33,TG34,TG35,TG36,TG37,TG38,TG40) %>% 
  mutate_if(is.character, as.numeric) %>%
  rowwise() %>%
  mutate(REO = sum(c_across(TG20:TG22)),
         RST = sum(c_across(TG9:TG13),TG38),
         FS = sum(c_across(TG29:TG33)),
         FA = sum(c_across(TG25:TG28)),
         INT = sum(c_across(TG34:TG37)),
         GOV = sum(TG23,TG24,TG40),
         ECON = sum(c_across(TG18:TG19)),
         SOC = sum(c_across(TG14:TG16))
         ) %>%
  select(!starts_with("TG")) %>%
  left_join(doc_cat_2, by = c('doc_id')) %>%

#Calculate nubmer of actors in each category per each country
  filter(assigned_category == 'Co-creation') %>%
  group_by(CountryLabel) %>%
  summarise(mean_actors_REO = mean(REO),
            mean_actors_RST = mean(RST),
            mean_actors_FS = mean(FS),
            mean_actors_FA = mean(FA),
            mean_actors_INT = mean(INT),
            mean_actors_GOV = mean(GOV),
            mean_actors_ECON = mean(ECON),
            mean_actors_SOC = mean(SOC)) 


Cocreate_actors %>% arrange(desc(mean_actors_REO)) %>% select(CountryLabel,mean_actors_REO) %>% head(5) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_RST)) %>% select(CountryLabel,mean_actors_RST) %>% head(5)) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_FS)) %>% select(CountryLabel,mean_actors_FS) %>% head(5)) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_FA)) %>% select(CountryLabel,mean_actors_FA) %>% head(5)) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_INT)) %>% select(CountryLabel,mean_actors_INT) %>% head(5)) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_GOV)) %>% select(CountryLabel,mean_actors_GOV) %>% head(5)) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_ECON)) %>% select(CountryLabel,mean_actors_ECON) %>% head(5)) %>%
  cbind(Cocreate_actors %>% arrange(desc(mean_actors_SOC)) %>% select(CountryLabel,mean_actors_SOC) %>% head(5)) %>%
  kbl() %>%
  kable_classic(full_width = F,font_size = 20) %>%
  save_kable("actors_cocreate.png")

```

```{r}
#Re-arranged by combining some 'TG's into a bigger category according to STIP classification of target groups
KT_actors <- doc_cat_2 %>%
  select(doc_id,TG9,TG10,TG11,TG12,TG13,TG14,TG15,TG16,TG17,TG18,TG19,TG20,TG21,TG22,TG23,TG24,TG25,TG26,TG27,TG28,TG29,TG30,TG31,TG32,TG33,TG34,TG35,TG36,TG37,TG38,TG40) %>% 
  mutate_if(is.character, as.numeric) %>%
  rowwise() %>%
  mutate(REO = sum(c_across(TG20:TG22)),
         RST = sum(c_across(TG9:TG13),TG38),
         FS = sum(c_across(TG29:TG33)),
         FA = sum(c_across(TG25:TG28)),
         INT = sum(c_across(TG34:TG37)),
         GOV = sum(TG23,TG24,TG40),
         ECON = sum(c_across(TG18:TG19)),
         SOC = sum(c_across(TG14:TG16))
         ) %>%
  select(!starts_with("TG")) %>%
  left_join(doc_cat_2, by = c('doc_id')) %>%

#Calculate nubmer of actors in each category per each country
  filter(assigned_category == 'Knowledge Transfer') %>%
  group_by(CountryLabel) %>%
  summarise(mean_actors_REO = mean(REO),
            mean_actors_RST = mean(RST),
            mean_actors_FS = mean(FS),
            mean_actors_FA = mean(FA),
            mean_actors_INT = mean(INT),
            mean_actors_GOV = mean(GOV),
            mean_actors_ECON = mean(ECON),
            mean_actors_SOC = mean(SOC)) 
  
KT_actors %>% arrange(desc(mean_actors_REO)) %>% select(CountryLabel,mean_actors_REO) %>% head(5) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_RST)) %>% select(CountryLabel,mean_actors_RST) %>% head(5)) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_FS)) %>% select(CountryLabel,mean_actors_FS) %>% head(5)) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_FA)) %>% select(CountryLabel,mean_actors_FA) %>% head(5)) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_INT)) %>% select(CountryLabel,mean_actors_INT) %>% head(5)) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_GOV)) %>% select(CountryLabel,mean_actors_GOV) %>% head(5)) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_ECON)) %>% select(CountryLabel,mean_actors_ECON) %>% head(5)) %>%
  cbind(KT_actors %>% arrange(desc(mean_actors_SOC)) %>% select(CountryLabel,mean_actors_SOC) %>% head(5)) %>%
  kbl() %>%
  kable_classic(full_width = F,font_size = 20) %>%
  save_kable("actors_KT.png")
```

#### Diversity of the themes?
1) Number of themes per each category
```{r}

doc_cat_2 %>%
  group_by(doc_id,assigned_category) %>%
  pivot_longer(48:99, names_to = 'Themes', values_to = 'presence') %>%
  filter(presence == 1) %>%
  summarise(num_themes = n()) %>%
  ungroup() %>%
  group_by(assigned_category) %>%
  summarise(avr_num_themes = mean(num_themes)) %>%
  kbl(longtable = T, booktabs = T) %>%
  kable_classic(full_width = F,font_size = 50) %>%
  column_spec(2, width = "8m") %>%
  save_kable("average_themes.png", self_contained = T)
  
```

2) Top 10 countries in each category
```{r}
#Co-creation
doc_cat_2 %>%
  #Calculate number of distinct themes for each country across all years (past til present) per each document
  group_by(doc_id,assigned_category,CountryLabel) %>%
  pivot_longer(48:99, names_to = 'Themes', values_to = 'presence') %>%
  filter(presence == 1,assigned_category == 'Co-creation')  %>%
    summarise(num_themes = n_distinct(Themes)) %>%
  #Calculate average number of distinct themes of all the documents for each country across all years (past til present)
  group_by(CountryLabel) %>%
  summarise(mean_themes = mean(num_themes)) %>%
  arrange(desc(mean_themes)) %>%
  head(10) %>%
  
  kbl(longtable = T) %>%
  kable_classic(full_width = F,font_size = 50) %>%
  save_kable("Themes_Cocreate.png")

```

```{r}
#Knowledge Transfer
doc_cat_2 %>%
  #Calculate number of distinct themes for each country across all years (past til present) per each document
  group_by(doc_id,assigned_category,CountryLabel) %>%
  pivot_longer(48:99, names_to = 'Themes', values_to = 'presence') %>%
  filter(presence == 1,assigned_category == 'Knowledge Transfer')  %>%
  summarise(num_themes = n_distinct(Themes)) %>%
  #Calculate average number of distinct themes of all the documents for each country across all years (past til present)
  group_by(CountryLabel) %>%
  summarise(mean_themes = mean(num_themes)) %>%
  arrange(desc(mean_themes)) %>%
  head(10)%>%
  kbl() %>%
  kable_classic(full_width = F,font_size = 50) %>%
  save_kable("Themes_KT.png")

```

3) Compare avr. no. themes within the same countries
```{r}
theme_country <- doc_cat_2 %>%
  group_by(doc_id,assigned_category,CountryLabel) %>%
  pivot_longer(48:99, names_to = 'Themes', values_to = 'presence') %>%
  filter(presence == 1,assigned_category == 'Co-creation')  %>%
  summarise(num_themes = n_distinct(Themes)) %>%
  group_by(CountryLabel) %>%
  summarise(total_themes = sum(num_themes),
            mean_themes = mean(num_themes)) %>%
  mutate(Category = 'Co-creation') %>%
  
  #join with knowledge transfer 
  rbind(doc_cat_2 %>%
  group_by(doc_id,assigned_category,CountryLabel) %>%
  pivot_longer(48:99, names_to = 'Themes', values_to = 'presence') %>%
  filter(presence == 1,assigned_category == 'Knowledge Transfer')  %>%
  summarise(num_themes = n_distinct(Themes)) %>%
  group_by(CountryLabel) %>%
  summarise(total_themes = sum(num_themes),
            mean_themes = mean(num_themes))%>%
  mutate(Category = 'Knowledge Transfer')) 


theme_country %>% filter(Category == 'Co-creation') %>% arrange(CountryLabel) %>%
  head(10)%>%
  kbl() %>%
  kable_classic(full_width = F,font_size = 50) %>%
  save_kable("Themes_Cocreate_countries_comparison.png")

```

```{r}
theme_country %>% filter(Category == 'Knowledge Transfer') %>% arrange(CountryLabel) %>% arrange(CountryLabel) %>%
  head(10)%>%
  kbl() %>%
  kable_classic(full_width = F,font_size = 50) %>%
  save_kable("Themes_KT_countries_comparison.png")
```

Bar plot of above themes data 
```{r}

theme_country %>%
  group_by(Category) %>%
  summarise(avr_themes = mean(mean_themes),
            stdv = sd(mean_themes)) %>%
  ggplot() +
  geom_bar(aes(x = Category, y = avr_themes), stat="identity", alpha=0.5)+
    geom_errorbar(aes(x=Category, ymin=avr_themes-stdv, ymax=avr_themes+stdv), width=0.4, colour="orange", alpha=0.9, size=1.3)
```

4) Average no. themes in 2021: Which countries do most co-creation this year (2021)? 
```{r}
doc_cat_2 %>%
  filter(StartDateYear == 2021) %>%
  group_by(doc_id,assigned_category,CountryLabel) %>%
  pivot_longer(48:99, names_to = 'Themes', values_to = 'presence') %>%
  filter(presence == 1,assigned_category == 'Co-creation') %>%
  summarise(num_themes = n()) %>%
  group_by(CountryLabel) %>%
  summarise(mean_themes = mean(num_themes)) %>%
  arrange(desc(mean_themes))
```

#### Length of implementation
Average length of year implemented: 
```{r}
doc_cat_2 %>%
  group_by(assigned_category) %>%
  summarise(avr_length = mean(year_length, na.rm = TRUE))
```
#### Yearly Budget range?
```{r}
doc_cat_2 %<>%
  mutate(budget_weight = case_when(YearlyBudgetRange == "Unknown" | YearlyBudgetRange == "Not applicable"~ 0,
                                   YearlyBudgetRange == "Less than 1M" ~ 0.005,
                                   YearlyBudgetRange == "1M-5M" ~ 0.01,
                                   YearlyBudgetRange == "5M-20M" ~ 0.05,
                                   YearlyBudgetRange == "20M-50M" ~ 0.2,
                                   YearlyBudgetRange == "50M-100M" ~ 0.5,
                                   YearlyBudgetRange == "100M-500M" ~ 1,
                                   YearlyBudgetRange == "More than 500M" ~ 5)) %>%
  relocate(budget_weight, .after = YearlyBudgetRange)

```

Budget allocated to each category across year (negative is co-creation)
Note: It may not be a good idea to plot the average budget across year because each country may allocate different amount of resources and budget in every year, and each year, there may be different number of countries putting up the policy initiatives. SO it's better to plot it against the countries to control for the individual heterogeneity - It's harder to know whether there's time heterogeneity, but differences between countries are more obvious (See more explanation on the next diagram). Nevertheless, below plot is just an example. 
```{r}
png(filename = paste0( getwd(), "/Plots/Initiatives/Budget_year.png"),width = 2000, height = 2000)

#Calculate the average weight of the budget allocated to policies in each country across all years
doc_cat_2 %>%
  group_by(StartDateYear,assigned_category) %>%
  summarise(num_policy = n(),
            sum_budget_weight = sum(1+budget_weight),
            avr_budget_weight = sum_budget_weight/num_policy) %>%

#Calculate the weight differences
  group_by(StartDateYear) %>%
  filter(assigned_category != 'Both') %>%
  summarise(Diff_budget_weight = diff(avr_budget_weight)) %>%
  drop_na(StartDateYear) %>%
  ggplot() +
  geom_bar(aes(x = StartDateYear, y = Diff_budget_weight,fill = StartDateYear), stat="identity", alpha=1)+
  xlab("Category") +
  ylab("DIfference in Budget weight") +
  theme(axis.text.x = element_text(size = 30,angle =0),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30),
         legend.position = 'none'
         ) +
    coord_flip()

dev.off()
```
Budget allocated to each category across countries. 
- This one assumes that every country is affected by the same crisis, e.g. financial crisis, COVID, etc. So the heterogeneity may be consistent. 
- However, this does not take into account the other effect such as country with high GDP like China or Western in which investment on the policy/project can be much more. Nor does it account for crisis happened in individual country such as flood or other disasters. 
```{r}
png(filename = paste0( getwd(), "/Plots/Initiatives/Budget_countries.png"),width = 2000, height = 2000)

  #Calculate the average weight of the budget allocated to policies in each country across all years
doc_cat_2 %>%
  group_by(CountryLabel,assigned_category) %>%
  summarise(num_policy = n(),
            sum_budget_weight = sum(1+budget_weight),
            avr_budget_weight = sum_budget_weight/num_policy) %>%

  #Calculate the weight differences
  group_by(CountryLabel) %>%
  filter(assigned_category != 'Both') %>%
  summarise(Diff_budget_weight = diff(avr_budget_weight)) %>%

  #Make category again so that you can them the same color in fill = 
  mutate(Category = ifelse(Diff_budget_weight < 0,"co-create", "knowledge transfer")) %>%
  ungroup() %>%
  
  ggplot() +
  geom_bar(aes(x = reorder(CountryLabel,Diff_budget_weight), y = Diff_budget_weight, fill = Category), stat="identity", alpha=1)+
  xlab("Category") +
  ylab("DIfference in Budget weight") +
  scale_fill_discrete(name="Category ",
                      labels = c("Co-create", "Knowledge Transfer")) +
  scale_fill_manual(values = c("#00ba38","#0b8fd3")) +
  theme(axis.text.x = element_text(size = 30,angle =0),
         axis.text.y = element_text(size = 30),
         axis.title.x = element_text(size = 35),
         axis.title.y = element_text(size = 35),
         legend.title = element_text(size = 35),
         legend.text = element_text(size = 30),
         legend.position = 'none'
         ) +
    coord_flip()

dev.off()
```

# 2. Network visualization of topics
Create a dataframe for network plotting
```{r}
Keyword <- All_cloud %>% as.data.frame()
Keyword_co <- Co_cloud %>% as.data.frame() 
Keyword_KT <- KT_cloud %>% as.data.frame() 
Keyword_NT <- NT_cloud %>% as.data.frame() 
```

```{r}
Keyword_matrix <- Keyword[,2:566] %>% as.matrix()
Co_matrix <- Keyword_co[,2:389] %>% as.matrix()
KT_matrix <- Keyword_KT[,2:451] %>% as.matrix()
NT_matrix <- Keyword_NT[,2:430] %>% as.matrix()

#Change row names into the corresponding InitiativeID
ID <- Keyword$doc_id
rownames(Keyword_matrix) <- ID

ID2 <- Keyword_co$doc_id
rownames(Co_matrix) <- ID2

ID3 <- Keyword_KT$doc_id
rownames(KT_matrix) <- ID3

ID4 <- Keyword_NT$doc_id
rownames(NT_matrix) <- ID4
```

```{r}
m_key_key <- Keyword_matrix %>% crossprod()
m_key_co <- Co_matrix %>% crossprod()
m_key_kt <- KT_matrix %>% crossprod()
m_key_nt <- NT_matrix %>% crossprod()

m_key_key[1:10,1:10] #first 10 rows
m_key_co[1:10,1:10]
```

```{r}
g_key <- m_key_key %>% as_tbl_graph(directed = FALSE) %N>%
  filter(!node_is_isolated()) %N>%
#Focus on nodes which have high connections/edges
  mutate(dgr = centrality_eigen(weights = weight))  %N>%
  filter(dgr > 0.02) %N>%
#Join with the assigned category
  left_join(Keyword_categories, by = 'name')


g_co <- m_key_co %>% as_tbl_graph(directed = FALSE) %N>%
  filter(!node_is_isolated()) %N>%
#Focus on nodes which have high connections/edges
  mutate(dgr = centrality_eigen(weights = weight))  %N>%
  filter(dgr > 0.03) %N>%
#Join with the assigned category
  left_join(Keyword_categories, by = 'name')

g_kt <- m_key_kt %>% as_tbl_graph(directed = FALSE) %N>%
  filter(!node_is_isolated()) %N>%
#Focus on nodes which have high connections/edges
  mutate(dgr = centrality_eigen(weights = weight))  %N>%
  filter(dgr > 0.05) %N>%
#Join with the assigned category
  left_join(Keyword_categories, by = 'name')
```

```{r}
#fix the coordinates
coords_tech_key <- g_kt %>% igraph::layout.fruchterman.reingold() %>% as_tibble(.name_repair = 'unique')
colnames(coords_tech_key) <- c("x", "y")
```



```{r}
tmp <- tempfile() #Run a temporary file and use rsvg_png to save the .png file in your directory file
svglite(tmp, width = 100, height = 100)

g_co %>%
  ggraph(layout = coords_tech_key) + 
  geom_edge_link(aes(width = weight), alpha = 1, colour = "grey") + 
  geom_node_point(aes(color = assigned_category,size = Tfidf_cocreate), alpha = 1)  + 
  geom_node_text(aes(label = name, size = Total_doc), repel = TRUE) +
  theme_graph()+
  coord_fixed()+
  theme(legend.text = element_text(size =  100), #changing legend text size
        legend.title = element_text(size = 100, face = "bold"),#changing legend title size
        plot.title = element_text(size=100))+
  scale_size_continuous( breaks = c(1,10,20,30,40,50,60,70, 80),
              range = c(5, 50)) + #adjust relative node size
  guides(colour = guide_legend(override.aes = list(size=60))) + #changing legend symbol size
  labs(title =paste('dgr > 0.03'),
       subtitle = '')


dev.off()

rsvg::rsvg_png(tmp,"Network_co_2.png")

```
```{r}
tmp <- tempfile() #Run a temporary file and use rsvg_png to save the .png file in your directory file
svglite(tmp, width = 100, height = 100)

g_kt %>%
  ggraph(layout = coords_tech_key) + 
  geom_edge_link(aes(width = weight), alpha = 1, colour = "grey") + 
  geom_node_point(aes(color = assigned_category,size = Tfidf_cocreate), alpha = 1)  + 
  geom_node_text(aes(label = name, size = Total_doc), repel = TRUE) +
  theme_graph()+
  coord_fixed()+
  theme(legend.text = element_text(size =  100), #changing legend text size
        legend.title = element_text(size = 100, face = "bold"),#changing legend title size
        plot.title = element_text(size=100))+
  scale_size_continuous( breaks = c(1,10,20,30,40,50,60,70, 80,90,100),
              range = c(5, 50)) + #adjust relative node size
  guides(colour = guide_legend(override.aes = list(size=60))) + #changing legend symbol size
  labs(title =paste('dgr > 0.05'),
       subtitle = '')


dev.off()

rsvg::rsvg_png(tmp,"Network_kt_2.png")
```
# 3. Venn diagram
```{r}
set_co <- Keyword_co[-1] %>% colnames()
set_kt <- Keyword_KT[-1] %>% colnames()
x = list(set_co,set_kt)

venn.diagram(x,width = 5000,height = 5000,cat.cex = 1.2,cex = 2,
             category.names = c("Co-creation","Knowledge Transfer"),
             filename = "venn_diagram_1.png",
             output=TRUE)


#Find non-overlapped keywords
#Co-creation
Cocreate_key <- set_co %>% as.data.frame() %>% anti_join(set_kt%>% as.data.frame(), by = ".") %>% left_join(Keyword_categories, by = c("."="name")) %>% arrange(desc(Tfidf_cocreate)) %>% rename(Co_creation = '.')
#Knowledge Transfer
KT_key <- set_kt %>% as.data.frame() %>% anti_join(set_co%>% as.data.frame(), by = ".") %>% left_join(Keyword_categories, by = c("."="name")) %>% arrange(desc(Tfidf_KT)) %>% rename(Knowledge_transfer = '.')
#Find overlapped keywords
Overlap_key <- set_co %>% as.data.frame() %>% inner_join(set_kt%>% as.data.frame(), by = ".") %>% left_join(Keyword_categories, by = c("."="name")) %>% rename(Overlap = '.')


write.csv(Cocreate_key,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\Plots\\Co_creation_Venn.csv"), row.names = FALSE)
write.csv(KT_key,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\Plots\\Knowledge_transfer_Venn.csv"), row.names = FALSE)
write.csv(Overlap_key,paste0("C:\\Users\\Katie_Sirinant\\Desktop\\Hackathon\\Plots\\Overlap_Venn.csv"), row.names = FALSE)

```

# 4. Network viz of indicators

## By themes
```{r}
#Make a new stip dataframe for conversion to matrix
stip_m <- stip %>% 
  select(InitiativeID,StartDateYear,TH42,TH43,TH47,TH46,TH44,TH41) %>% 
  mutate_if(is.character, as.numeric) %>% 
  filter(StartDateYear == '2017')#filter year

#Add a n_count column to see how many themes are present
stip_m$n_count <- rowSums(stip_m[3:8]) 

#Filter out initiatives that do not consist of these 6 themes
stip_m <- stip_m %>% 
  filter(n_count > 0) 

#Make a matrix 
m_int_TH <- stip_m %>% 
  select(TH42,TH43,TH47,TH46,TH44,TH41) %>%
  as.matrix()

#Change row names into the corresponding InitiativeID
ID <- stip_m$InitiativeID
rownames(m_int_TH) <- ID

```


Create an initativeID*initiativeID matrix
```{r}
m_int_int <- m_int_TH %*% t(m_int_TH) 

m_int_int[1:10,1:10] #first 10 rows

```

Filter only nodes with more than 2 links (weights) between two initiatives
```{r}
m_int_int[m_int_int[]> 2]
```

```{r}
g_int <- m_int_int %>% as_tbl_graph(directed = FALSE) %N>%
  mutate(dgr = centrality_eigen(weights = weight)) %N>%
   mutate(name = as.numeric(name))
```

Add a community 
```{r}
g_int <- g_int %N>% 
  mutate(community = group_edge_betweenness(weights = weight, directed = FALSE) %>% as.factor()) 
```
Add countries info
```{r}
g_int <- g_int %N>% left_join(stip %>% select(InitiativeID,NameEnglish,CountryLabel,YearlyBudgetRange,all_texts), by = c('name'='InitiativeID'))

g_int
```


Visualize the variables of the nodes by community
```{r}
g_int %N>% as_tibble() %>% filter(community == 1)
```

```{r}
#fix the coordinates
coords_tech <- g_int %>% igraph::layout.fruchterman.reingold() %>% as_tibble(.name_repair = 'unique')
colnames(coords_tech) <- c("x", "y")
```


```{r}
tmp <- tempfile() #Run a temporary file and use rsvg_png to save the .png file in your directory file
svglite(tmp, width = 100, height = 100)

g_int %>%
  ggraph(layout = coords_tech) + 
  geom_edge_link(aes(width = weight), alpha = 0.5, colour = "grey") + 
  geom_node_point(aes(color = community, size = dgr))  + 
  geom_node_text(aes(label = name), size = 25, repel = TRUE) +
  theme_graph()+
  coord_fixed()+
  theme(legend.text = element_text(size =  100), #changing legend text size
        legend.title = element_text(size = 100, face = "bold"),#changing legend title size
        plot.title = element_text(size=100))+
  scale_size( breaks = c(1, 10, 25, 40),
              range = c(20, 40)) + #adjust relative node size
  guides(colour = guide_legend(override.aes = list(size=60))) + #changing legend symbol size
  labs(title =paste('Policy initiatives network started in 2017'),
       subtitle = '')


dev.off()

rsvg::rsvg_png(tmp,"policy_initiative_network_2017.png")

```

## By target groups
```{r}
#Make a new stip dataframe for conversion to matrix
stip_m2 <- stip %>% 
  select(InitiativeID,StartDateYear,TG9,TG10,TG11,TG12,TG13,TG14,TG15,TG16,TG17,TG18,TG19,TG20,TG21,TG22,TG23,TG24,TG25,TG26,TG27,TG28,TG29,TG30,TG31,TG32,TG33,TG34,TG35,TG36,TG37,TG38,TG40) %>% 
  mutate_if(is.character, as.numeric) %>% 
  filter(StartDateYear == '2000') #filter year

#Count the number of actors based on the categories defined in STIP codebook
stip_m2 %<>% 
  rowwise() %>%
  mutate(REO = sum(c_across(TG20:TG22)),
         RST = sum(c_across(TG9:TG13),TG38),
         FS = sum(c_across(TG29:TG33)),
         FA = sum(c_across(TG25:TG28)),
         INT = sum(c_across(TG34:TG37)),
         GOV = sum(TG23,TG24,TG40),
         ECON = sum(c_across(TG18:TG19)),
         SOC = sum(c_across(TG14:TG16))
         ) %>%
  select(!starts_with("TG")) %>%
  ungroup()

#Add a n_count column to see how many target groups are present in total
stip_m2$n_count <- rowSums(stip_m2[3:10]) 

#Make a matrix 
m_int_TG <- stip_m2 %>% 
  #select(TG9,TG10,TG11,TG12,TG13,TG14,TG15,TG16,TG17,TG18,TG19,TG20,TG21,TG22,TG23,TG24,TG25,TG26,TG27,TG28,TG29,TG30,TG31,TG32,TG33,TG34,TG35,TG36,TG37,TG38,TG40) %>%
 select(REO,RST,FS,FA,INT,GOV,ECON,SOC) %>%
  as.matrix()

#Change row names into the corresponding InitiativeID
ID <- stip_m2$InitiativeID
rownames(m_int_TG) <- ID

```

```{r}
stip_m2
```

```{r}
m_int_TG[1:10,]
```

Create an initativeID*initiativeID matrix. 
```{r}
#m_int_int <- m_int_TG %*% t(m_int_TG)  #Network between initiative with combined number of actors. Not a good idea unless you make one matrix (network) per one actor
m_actor <- m_int_TG %>% crossprod() %>% as.matrix() #Network between actors by the number of initiatives

#m_int_int[1:10,1:10] #first 10 rows
m_actor
```
Matrix by relatedness
```{r}
#m_int_rel <- m_int_int %>% 
#  relatedness(method = "cosine")

m_actor_rel <- m_actor %>%
  relatedness(method = "cosine")
m_actor_rel
```

```{r}
g_int <- m_actor_rel %>% as_tbl_graph(directed = FALSE) %N>%
  mutate(dgr = centrality_eigen(weights = weight)) %N>%
#   mutate(name = as.numeric(name)) %N>%
  filter(!node_is_isolated()) 
```

Add a community 
```{r}
g_int <- g_int %N>% 
  mutate(community = group_edge_betweenness(weights = weight, directed = FALSE) %>% as.factor()) 
```
Add countries info
```{r}
#g_int <- g_int %N>% left_join(stip %>% select(InitiativeID,NameEnglish,CountryLabel,YearlyBudgetRange,all_texts), by = c('name'='InitiativeID'))

#g_int
```


Visualize the variables of the nodes by community
```{r}
g_int %N>% as_tibble() %>% filter(community == 1)
```

```{r}
#fix the coordinates
coords_tech <- g_int %>% igraph::layout.fruchterman.reingold() %>% as_tibble(.name_repair = 'unique')
colnames(coords_tech) <- c("x", "y")
```


```{r}
tmp <- tempfile() #Run a temporary file and use rsvg_png to save the .png file in your directory file
svglite(tmp, width = 100, height = 100)

g_int %>%
  ggraph(layout = coords_tech) + 
  geom_edge_link(aes(width = weight), alpha = 0.5, colour = "grey") + 
  geom_node_point(aes(color = name, size = dgr))  + 
  geom_node_text(aes(label = name), size = 25, repel = TRUE) +
  theme_graph()+
  coord_fixed()+
  theme(legend.text = element_text(size =  100), #changing legend text size
        legend.title = element_text(size = 100, face = "bold"),#changing legend title size
        plot.title = element_text(size=100))+
  scale_edge_width(breaks = c(0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4), #adjust relative edge size
              range = c(2, 50)) +
  scale_size( breaks = c(0,0.2,0.4,0.6,0.8,1),
              range = c(5, 40)) + #adjust relative node size
  guides(colour = guide_legend(override.aes = list(size=60))) + #changing legend symbol size
  labs(title =paste('Actors relatedness network linked by policy initiatives in 2000'),
       subtitle = '')


dev.off()

rsvg::rsvg_png(tmp,"policy_initiative_network_2000_actors.png")

```
## By organizations

Detail of the organizations (Named Entity Recognition)
```{r}
library(stringr)
head(stip_dfm$NameEnglish,10)
```

Not working! Need to group the keywords in 'Tags' according to 'Co-creation' and 'Knowledge Transfer' category
```{r}
m_org <- stip %>% 
  select(InitiativeID,NameEnglish,CountryLabel,StartDateYear,Tags) %>%
  drop_na(Tags) %>% 
  mutate(co_creation = ifelse(str_detect(Tags,'co-creation'),1,0),
         knowledge_transfer = ifelse(str_detect(Tags,'knowledge transfer'),1,0)) %>%
 # group_by(NameEnglish) %>% summarise(count = sum(co_creation))

m_org_co <- m_org %>% 
  select(co_creation) %>%
  as.matrix()

ID <- m_org$NameEnglish
rownames(m_org_co) <- ID

```

```{r}
m_org_co <- tcrossprod(m_org_co)
m_org_co[1:10,1:10]
```
