---
title: "Hackathon - STI.Scoreboard indicators"
output: html_document
date: '2022-05-24'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.showtext = TRUE)
```

#SET UP
```{r}
### general options
Sys.setenv(LANG = "en")
options("scipen" = 100, "digits" = 4) # override R's tendency to use scientific notation

### Clean workspace
#rm(list=ls())
#graphics.off()

### Load packages (maybe need to be installed first)
# Standard
library(tidyverse) # General DS toolkit
library(magrittr) # For advanced piping

# Databases
#library(DBI) # GEneral R database interface
#library(RPostgres) # PostgreSQL interface driver 
library(dbplyr) # for dplyr with databases

# Dataviz
#library(kableExtra)
#library(treemapify)
#library(gplots)
library(ggraph) #Network
#library(ggrepel)
#library(hrbrthemes) #Beautiful theme
#library(viridis) #Beautiful theme
#library(car) #scatterplot() package
#library(plotly) #interactive plots
#library(htmlwidgets) #interactive widgets 
library(svglite)  # for saving pictures in svg clearer format (can convert to png) 
library(rsvg)
#library(ggpubr)
#library(interplot)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)

#Network
library(tidygraph)


# Economic Complexity
library(EconGeo)

#Regression
#library(plm)
#library(stargazer) #beautiful Latex, HTML, ASCII tables
#library(lmtest) #coeftest()
#library(sandwich) #vcovHC
#library(sjPlot) # Plot results (tab_model)
#library(sjmisc) #For descr() and other fun complementary with dplyr http://strengejacke.de/sjmisc-cheatsheet.pdf
#library(html2latex) # Convert tab_model html tables to tex and pdf 
#library(bife) #Fixed effects logit/probit
#library(stargazer)

#Solve R Fatal Error
#options("error" = function () {
#.rs.recordTraceback(TRUE, 5, .rs.enqueueError)
#})
```

# 1. Descriptive Text: STIP Compass surveys
More data: https://stip.oecd.org/stip/pages/stipDataLab
```{r}
library(readr)


url <- 'https://stip.oecd.org/assets/downloads/STIP_Survey.csv'   #2021

#download the dataset Or download from the link above
download.file(url, destfile = 'stip_2021.csv', mode = 'wb')


#load the dataset into our working environment
stip_0 <- read_delim('stip_2021.csv', '|', escape_double = FALSE, trim_ws = TRUE)

```

Prepare the dataset
```{r}
#Most columns with info on instruments start with the Letter 'F' followed by a number & a few more instruments
instrument <- stip_0[,grepl('^[F][0-9]', (names(stip_0)))] %>% cbind(stip_0[,!grepl('Instrument', (names(stip_0)))])
```

```{r}
# Removes all columns with instrument (start with F)
stip <- stip_0[,!grepl('^[F][0-9]', (names(stip_0)))]

#There are a few more columns with information on instruments. We remove them, too for the sake of coherence
stip <- stip_0[,!grepl('Instrument', (names(stip_0)))]

#This code identifies unique Initiative IDs. When multiple rows have the same initiative IDs, it retains only one of them. Since we have already removed all the information on instruments, no information is lost by retaining each initiative only once
stip <- stip %>%
  distinct(InitiativeID, .keep_all = T)

names(stip)
```

The first row of the dataset does not contain actual data, but descriptions of the variables. We extract this row and create a dataframe from it that we call our codebook. 
```{r}
codebook <- as.data.frame(t(stip[1,])) %>%
  rownames_to_column()

names(codebook) <- c('Variable', 'Code')

#...remove the first row from the dataset: 
stip <- stip[-1, ]

#take a look at the codebook
head(codebook) #The first few variables names are mostly self-explanatory 
```

Add some new columns
```{r}
stip <- stip %>%
  mutate(InitiativeID = as.numeric(gsub('http://stip.oecd.org/2021/data/policyInitiatives/', '', stip$InitiativeID))) %>%
  mutate(year_length = as.numeric(EndDateYear)-as.numeric(StartDateYear)) %>%
  relocate(year_length, .after = EndDateYear)

```

Combine short description with objectives to a new all_texts column
```{r}
#this creates a vector with the names of all columns we wish to unite
cols <- c('ShortDescription', names(stip)[grepl('Objectives', names(stip))])

#this unites these columns in the new column 'all_texts'
stip$all_texts <- apply(stip[ ,cols], 1, paste, collapse = ' ')

#take a look at the first few new documents (i.e. the pieces of textual data that we will analyse)
head(stip$all_texts, 3)
```
Create corpus
Note to myself: a corpus contains text and speech data that can be used to train AI and machine learning systems
```{r}
stip_corp <- corpus(stip, docid_field = 'InitiativeID', text_field = 'all_texts')

#take a look
stip_corp
```

```{r}
stip_dfm <- dfm(stip_corp)

stip_dfm <- stip_dfm %>%
  dfm_remove(stopwords('english'), min_nchar = 3) %>%
  dfm_remove(pattern = '(?<=\\d{1,9})\\w+', valuetype = 'regex' )

#Take a look: This dfm has still more 10000 features
stip_dfm  
```
Reduce the number of features in the dfm during pre-processing.
```{r}
stip_dfm  <- stip_dfm %>% 
  dfm_wordstem() %>% #stem the dfm
  dfm_trim(min_docfreq = 0.01,  docfreq_type = 'prop') # retain only words included in at least 1% of documents
  #dfm_subset(ntoken(stip_dfm) >= 10) # remove documents with less than 10 words

#Take a look again: Now, we have substantially reduced the number of features to less than 1000
stip_dfm
```
The dataset also contains a column with innovation-related keywords for each initiative (from a dedicated vocabulary of concepts). This is highly useful for the analysis, so we generate a second dfm from it. We generate this dfm in another way than the previous one since the unit of analysis in this case are not words, but keywords often consisting of multi-word expressions.
```{r}
tag_dfm <- tokenizers::tokenize_regex(stip$Tags, pattern = '¬') %>%
  as.tokens() %>%
  dfm() %>%
  dfm_remove(min_nchar = 3) 

rownames(tag_dfm) <- stip$InitiativeID
docvars(tag_dfm) <- stip

tag_dfm


```
Detail of tag_dfm
```{r}
ndoc(tag_dfm) #number of docs
nfeat(tag_dfm) #number of features
head(docnames(tag_dfm))
head(featnames(tag_dfm),10)
```
Detail of the organizations (Named Entity Recognition)
```{r}
tokenizers::tokenize_regex(stip$NameEnglish, pattern = '¬') %>%
  as.tokens() %>%
  dfm() 
#  dfm_remove(min_nchar = 3) 
```

## Analyze text data
```{r}
textplot_wordcloud(stip_dfm)
```

```{r}
textplot_wordcloud(tag_dfm)
```
How does language in different subsets of policy initiatives differ?
```{r}
#e.g. From the codebook: TH31  'Financial support to business R&D and innovation' 
fs_keyness <- textstat_keyness(stip_dfm, 
                              target = stip_dfm$TH31 == 1)
textplot_keyness(fs_keyness)
```
Considering only documents in the dataset linked to this theme and then compare the initiatives from Canada to all the others.
```{r}
fs_dfm <- dfm_subset(stip_dfm, stip_dfm$TH31 == 1) 
  
can_keyness <- textstat_keyness(dfm_remove(fs_dfm, pattern = c('canada', 'canadian')), 
                              target = fs_dfm$CountryCode == 'CAN')

textplot_keyness(can_keyness)
```
Compare the documents from different countries.
CAUTION: 1) The comparison below does not consider whether some countries report more information on particular themes or survey questions than others. 2) This analysis assigns similar weight to all initiatives
```{r}
#create a dfm that merges all documents by country
dfm_countries <- dfm_group(stip_dfm, groups = CountryCode)

#computes distances between documents from different countries
tstat_dist <- as.dist(textstat_dist(dfm_countries))

#cluster countries based on these distances
user_clust <- hclust(tstat_dist)

plot(user_clust, cex = 0.5)
```


Find duplicated stip (No duplicated InitiativeID but NameEnglish)
```{r}
stip %>% 
  group_by(NameEnglish) %>% 
  filter(n()>1)
```

# 2. Quantitative data: STIP Scoreboard using SDMX  
Get 1 STI indicator
```{r}
library(rsdmx)
SdmxQuery <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/MSTI_PUB/G_XGDP.OECD/all?startTime=2014&endTime=2022"
Sdmxdata <- readSDMX(SdmxQuery)
SdmxDF <- as.data.frame(Sdmxdata)

```

Get several STI indicators
```{r}
# list of SDMX queries 

ListeQueries <- read.csv("https://stiplab.github.io/datastories/STI.Scoreboard/Inventory.csv", header = TRUE, sep = ",")
head(ListeQueries,5)
```
```{r}

# Create function for a dataframe that will host the results of the different queries

getSDMX <- function(sdmx_query) {
 SdmxQuery <- paste0("https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/",sdmx_query)
 SdmxDF <- readSDMX(SdmxQuery) %>% as.data.frame()

}

```

## Pick initiative
One initiative can have many policies. 
```{r}
QuantiIndicDF <- ListeQueries[ListeQueries$STIPCategoryCode == "TH41",] #Policy initiatives: Science-industry knowledge transfer and sharing|Transfer and linkages strategies


head(QuantiIndicDF,5)
```

```{r}
# creating a dataframe that will host the results
Results <- NULL

#looping on the SDMX queries files to retrieve all the series
for(Extraction in 1:nrow(QuantiIndicDF)) { 
  sdmx_quer <-QuantiIndicDF[Extraction,"SDMXqueries"]
  SdmxQueryDF<-getSDMX(sdmx_quer)
  INDICATOR<- QuantiIndicDF[Extraction,"SerieCode"]
  COU<-QuantiIndicDF[Extraction,"Location"]
    if("INDICATOR" %in% colnames( SdmxQueryDF))
  {
    SdmxQueryDF<-subset( SdmxQueryDF, select = -INDICATOR)
  } 
  SdmxQueryDF2<- cbind(SdmxQueryDF,INDICATOR)
  SdmxFormated <-SdmxQueryDF2 %>% rename(COUNTRY =COU, YEAR=obsTime, Value=obsValue, INDICATOR= INDICATOR)
  keep_cols = c("COUNTRY", "YEAR","Value", "INDICATOR")
  SdmxFormated2 <-SdmxFormated[,keep_cols]
  #Results <- rbind(Results, SdmxFormated2)
  Results <- bind_rows(Results, SdmxFormated2)
  
}

#let's visually check 
tail(Results,5)
head(Results,5)
```

Full label of each indicator in Results dataframe
Glossary: https://www.oecd.org/sti/inno/Frascati-2015-Glossary.pdf
https://nghoussoub.com/2012/03/06/everything-you-wanted-to-know-about-gerd-berd-goverd-and-herd/

GOVERD financed by the business enterprise sector: represents the component of (Gross domestic expenditure on R&D) GERD incurred by units belonging to the Government sector. 

HERD: represents the component of GERD incurred by units belonging to the Higher education sector. 
```{r}
Label<-Results %>% distinct(INDICATOR) %>% right_join(QuantiIndicDF %>% select(SerieCode,IndicatorLabel), by = c('INDICATOR'='SerieCode')) 
Label
```

Plot
```{r}
#select data for a given indicator and year
fig_df<-Results[Results$INDICATOR == 'H_XFB' & Results$YEAR == 2020, ]

library(ggplot2)
# Basic barplot that sorts the countries in descending order
p<-ggplot(data=fig_df, aes(x=reorder(COUNTRY, -Value), y=Value)) +
  geom_bar(stat="identity") +
  xlab("Country") + 
  ylab("% of total HERD") + 
  ggtitle(Label%>%filter(INDICATOR == 'H_XFB')%>%select(IndicatorLabel))
p
```

# 3. Network visualization

## By themes
```{r}
#Make a new stip dataframe for conversion to matrix
stip_m <- stip %>% 
  select(InitiativeID,StartDateYear,TH42,TH43,TH47,TH46,TH44,TH41) %>% 
  mutate_if(is.character, as.numeric) %>% 
  filter(StartDateYear == '2017')#filter year

#Add a n_count column to see how many themes are present
stip_m$n_count <- rowSums(stip_m[3:8]) 

#Filter out initiatives that do not consist of these 6 themes
stip_m <- stip_m %>% 
  filter(n_count > 0) 

#Make a matrix 
m_int_TH <- stip_m %>% 
  select(TH42,TH43,TH47,TH46,TH44,TH41) %>%
  as.matrix()

#Change row names into the corresponding InitiativeID
ID <- stip_m$InitiativeID
rownames(m_int_TH) <- ID

```

```{r}
stip_m
```

Create an initativeID*initiativeID matrix
```{r}
m_int_int <- m_int_TH %*% t(m_int_TH) 

m_int_int[1:10,1:10] #first 10 rows

```

Filter only nodes with more than 2 links (weights) between two initiatives
```{r}
m_int_int[m_int_int[]> 2]
```
```{r}
g_int <- m_int_int %>% as_tbl_graph(directed = FALSE) %N>%
  mutate(dgr = centrality_eigen(weights = weight)) %N>%
   mutate(name = as.numeric(name))
```

Add a community 
```{r}
g_int <- g_int %N>% 
  mutate(community = group_edge_betweenness(weights = weight, directed = FALSE) %>% as.factor()) 
```
Add countries info
```{r}
g_int <- g_int %N>% left_join(stip %>% select(InitiativeID,NameEnglish,CountryLabel,YearlyBudgetRange,all_texts), by = c('name'='InitiativeID'))

g_int
```


Visualize the variables of the nodes by community
```{r}
g_int %N>% as_tibble() %>% filter(community == 1)
```

```{r}
#fix the coordinates
coords_tech <- g_int %>% igraph::layout.fruchterman.reingold() %>% as_tibble(.name_repair = 'unique')
colnames(coords_tech) <- c("x", "y")
```


```{r}
tmp <- tempfile() #Run a temporary file and use rsvg_png to save the .png file in your directory file
svglite(tmp, width = 100, height = 100)

g_int %>%
  ggraph(layout = coords_tech) + 
  geom_edge_link(aes(width = weight), alpha = 0.5, colour = "grey") + 
  geom_node_point(aes(color = community, size = dgr))  + 
  geom_node_text(aes(label = name), size = 25, repel = TRUE) +
  theme_graph()+
  coord_fixed()+
  theme(legend.text = element_text(size =  100), #changing legend text size
        legend.title = element_text(size = 100, face = "bold"),#changing legend title size
        plot.title = element_text(size=100))+
  scale_size( breaks = c(1, 10, 25, 40),
              range = c(20, 40)) + #adjust relative node size
  guides(colour = guide_legend(override.aes = list(size=60))) + #changing legend symbol size
  labs(title =paste('Policy initiatives network started in 2017'),
       subtitle = '')


dev.off()

rsvg::rsvg_png(tmp,"policy_initiative_network_2017.png")

```
## By target groups
```{r}
#Make a new stip dataframe for conversion to matrix
stip_m2 <- stip %>% 
  select(InitiativeID,StartDateYear,TG9,TG10,TG11,TG12,TG13,TG14,TG15,TG16,TG17,TG18,TG19,TG20,TG21,TG22,TG23,TG24,TG25,TG26,TG27,TG28,TG29,TG30,TG31,TG32,TG33,TG34,TG35,TG36,TG37,TG38,TG40) %>% 
  mutate_if(is.character, as.numeric) %>% 
  filter(StartDateYear == '2000') #filter year

#Count the number of actors based on the categories defined in STIP codebook
stip_m2 %<>% 
  rowwise() %>%
  mutate(REO = sum(c_across(TG20:TG22)),
         RST = sum(c_across(TG9:TG13),TG38),
         FS = sum(c_across(TG29:TG33)),
         FA = sum(c_across(TG25:TG28)),
         INT = sum(c_across(TG34:TG37)),
         GOV = sum(TG23,TG24,TG40),
         ECON = sum(c_across(TG18:TG19)),
         SOC = sum(c_across(TG14:TG16))
         ) %>%
  select(!starts_with("TG")) %>%
  ungroup()

#Add a n_count column to see how many target groups are present in total
stip_m2$n_count <- rowSums(stip_m2[3:10]) 

#Make a matrix 
m_int_TG <- stip_m2 %>% 
  #select(TG9,TG10,TG11,TG12,TG13,TG14,TG15,TG16,TG17,TG18,TG19,TG20,TG21,TG22,TG23,TG24,TG25,TG26,TG27,TG28,TG29,TG30,TG31,TG32,TG33,TG34,TG35,TG36,TG37,TG38,TG40) %>%
 select(REO,RST,FS,FA,INT,GOV,ECON,SOC) %>%
  as.matrix()

#Change row names into the corresponding InitiativeID
ID <- stip_m2$InitiativeID
rownames(m_int_TG) <- ID

```

```{r}
stip_m2
```
```{r}
m_int_TG[1:10,]
```

Create an initativeID*initiativeID matrix. 
```{r}
#m_int_int <- m_int_TG %*% t(m_int_TG)  #Network between initiative with combined number of actors. Not a good idea unless you make one matrix (network) per one actor
m_actor <- m_int_TG %>% crossprod() %>% as.matrix() #Network between actors by the number of initiatives

#m_int_int[1:10,1:10] #first 10 rows
m_actor
```
Matrix by relatedness
```{r}
#m_int_rel <- m_int_int %>% 
#  relatedness(method = "cosine")

m_actor_rel <- m_actor %>%
  relatedness(method = "cosine")
m_actor_rel
```

```{r}
g_int <- m_actor_rel %>% as_tbl_graph(directed = FALSE) %N>%
  mutate(dgr = centrality_eigen(weights = weight)) %N>%
#   mutate(name = as.numeric(name)) %N>%
  filter(!node_is_isolated()) 
```

Add a community 
```{r}
g_int <- g_int %N>% 
  mutate(community = group_edge_betweenness(weights = weight, directed = FALSE) %>% as.factor()) 
```
Add countries info
```{r}
#g_int <- g_int %N>% left_join(stip %>% select(InitiativeID,NameEnglish,CountryLabel,YearlyBudgetRange,all_texts), by = c('name'='InitiativeID'))

#g_int
```


Visualize the variables of the nodes by community
```{r}
g_int %N>% as_tibble() %>% filter(community == 1)
```

```{r}
#fix the coordinates
coords_tech <- g_int %>% igraph::layout.fruchterman.reingold() %>% as_tibble(.name_repair = 'unique')
colnames(coords_tech) <- c("x", "y")
```


```{r}
tmp <- tempfile() #Run a temporary file and use rsvg_png to save the .png file in your directory file
svglite(tmp, width = 100, height = 100)

g_int %>%
  ggraph(layout = coords_tech) + 
  geom_edge_link(aes(width = weight), alpha = 0.5, colour = "grey") + 
  geom_node_point(aes(color = name, size = dgr))  + 
  geom_node_text(aes(label = name), size = 25, repel = TRUE) +
  theme_graph()+
  coord_fixed()+
  theme(legend.text = element_text(size =  100), #changing legend text size
        legend.title = element_text(size = 100, face = "bold"),#changing legend title size
        plot.title = element_text(size=100))+
  scale_edge_width(breaks = c(0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4), #adjust relative edge size
              range = c(2, 50)) +
  scale_size( breaks = c(0,0.2,0.4,0.6,0.8,1),
              range = c(5, 40)) + #adjust relative node size
  guides(colour = guide_legend(override.aes = list(size=60))) + #changing legend symbol size
  labs(title =paste('Actors relatedness network linked by policy initiatives in 2000'),
       subtitle = '')


dev.off()

rsvg::rsvg_png(tmp,"policy_initiative_network_2000_actors.png")

```
## By organizations
```{r}

```



